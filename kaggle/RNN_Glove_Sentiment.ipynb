{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://www.kaggle.com/kuldeep7688/simple-rnn-using-glove-embeddings-in-pytorch\n",
    "\n",
    "it uses TorchText\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyprind\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparing data for train, validation and test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  A very, very, very slow-moving, aimless movie ...       0\n",
      "1  Not sure who was more lost - the flat characte...       0\n",
      "2  Attempting artiness with black & white and cle...       0\n",
      "3       Very little music or anything to speak of.         0\n",
      "4  The best scene in the movie was when Gerardo i...       1\n",
      "(748, 2)\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_csv(\"../sentiment labelled sentences/imdb_labelled.txt\",\n",
    "                      header=None, sep='\\t')\n",
    "cols = [\"text\", \"target\"]\n",
    "main_df.columns = cols\n",
    "print(main_df.head())\n",
    "classes = {0:\"negative\", 1:\"positive\"}\n",
    "print(main_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    386\n",
      "0    362\n",
      "Name: target, dtype: int64\n",
      "negative class shape: (362, 2)\n",
      "positive class shape: (386, 2)\n"
     ]
    }
   ],
   "source": [
    "print(main_df.target.value_counts())\n",
    "neg_class = main_df.loc[main_df.target == 0, :]\n",
    "pos_class = main_df.loc[main_df.target == 1, :]\n",
    "print(\"negative class shape:\",neg_class.shape)\n",
    "print(\"positive class shape:\",pos_class.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (348, 2)\n",
      "1    186\n",
      "0    162\n",
      "Name: target, dtype: int64\n",
      "valid shape (200, 2)\n",
      "1    100\n",
      "0    100\n",
      "Name: target, dtype: int64\n",
      "test shape: (200, 2)\n",
      "1    100\n",
      "0    100\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# preparing balanced test and validation set\n",
    "# splitting test and train\n",
    "test_negative = neg_class.iloc[:100, :]\n",
    "test_positive = pos_class.iloc[:100, :]\n",
    "\n",
    "valid_negative = neg_class.iloc[100:200, :]\n",
    "valid_positive = pos_class.iloc[100:200, :]\n",
    "\n",
    "train_negative = neg_class.iloc[200:, :]\n",
    "train_positive = pos_class.iloc[200:, :]\n",
    "\n",
    "train = pd.concat([train_negative, train_positive], axis = 0)\n",
    "print(\"train shape:\",train.shape)\n",
    "print(train.target.value_counts())\n",
    "\n",
    "valid = pd.concat([valid_negative, valid_positive], axis=0)\n",
    "print(\"valid shape\",valid.shape)\n",
    "print(valid.target.value_counts())\n",
    "\n",
    "test = pd.concat([test_negative, test_positive], axis=0)\n",
    "print(\"test shape:\",test.shape)\n",
    "print(test.target.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving files to disk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir torchtext_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train.to_csv(\"torchtext_data/train.csv\", index=False)\n",
    "test.to_csv(\"torchtext_data/test.csv\", index=False)\n",
    "valid.to_csv(\"torchtext_data/valid.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Free up some memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-7489b1815b09>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdel\u001B[0m \u001B[0mmain_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_positive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_negative\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_positive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_negative\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_positive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_negative\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'main_df' is not defined"
     ]
    }
   ],
   "source": [
    "del main_df, train, test, valid, train_positive, train_negative, test_positive, test_negative, valid_positive, valid_negative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [tok for tok in nltk.word_tokenize(text)]\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.LabelField(dtype=torch.long, sequential=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading train, test and validation data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 348\n",
      "Number of validation examples: 200\n",
      "Number of testing examples: 200\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "    path=\"torchtext_data/\", train=\"train.csv\", validation=\"valid.csv\", test=\"test.csv\",\n",
    "    format=\"csv\", skip_header=True,\n",
    "    fields=[(\"text\", TEXT), (\"target\", LABEL)]\n",
    ")\n",
    "\n",
    "print(\"Number of training examples: {}\".format(len(train_data)))\n",
    "print(\"Number of validation examples: {}\".format(len(valid_data)))\n",
    "print(\"Number of testing examples: {}\".format(len(test_data)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the GloVe embeddings using the train vocalubary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 400000/400001 [00:14<00:00, 26922.49it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, vectors=torchtext.vocab.Vectors(\"../glove.6B/glove.6B.50d.txt\"),\n",
    "                 max_size=20000, min_freq=10)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 92\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique tokens in TEXT vocabulary: {}\".format(len(TEXT.vocab)))\n",
    "print(\"Unique tokens in LABEL vocabulary: {}\".format(len(LABEL.vocab)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start with the Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "#keep in mind the sort_key option\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),\n",
    "    batch_size=BATCH_SIZE, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'0': 162, '1': 186})"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dims, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dims, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        assert torch.equal(output[-1, :, :], hidden.squeeze(0))\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 374\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the pretrained embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([92, 50])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data = pretrained_embeddings.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Give weights to the classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., 15.])\n"
     ]
    }
   ],
   "source": [
    "class_weights = torch.tensor([1.0, 15.0]).to(device)\n",
    "print(class_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=2e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Evaluating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    returns accuracy per batch, i.e., if you get 8/10 right, this return 0.8, not 8\n",
    "    :param preds:\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    preds, ind = torch.max(F.softmax(preds, dim=-1), 1)\n",
    "    correct = (ind == y).float()\n",
    "    acc = correct.sum()/float(len(correct))\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(iterator), bar_char=\"█\")\n",
    "    for batch in iterator:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(0)\n",
    "        loss = criterion(predictions, batch.target)\n",
    "        acc = binary_accuracy(predictions, batch.target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        bar.update()\n",
    "\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(iterator), bar_char=\"█\")\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(0)\n",
    "            loss = criterion(predictions, batch.target)\n",
    "            acc = binary_accuracy(predictions, batch.target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            bar.update()\n",
    "\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n",
      "0% [██████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "0% [██████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n",
      "0% [██████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:1 | Train Loss: 0.4528486678997676 | Train Acc: 46.66666669978036% | Val. Loss: 0.4330769807100296 | Val. Acc: 50.0% |\n",
      "\n",
      "| Epoch:2 | Train Loss: 0.430962140361468 | Train Acc: 46.25000043047799% | Val. Loss: 0.410518479347229 | Val. Acc: 50.0% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    print('| Epoch:{} | Train Loss: {} | Train Acc: {}% | Val. Loss: {} | Val. Acc: {}% |'\n",
    "          .format(epoch+1, train_loss, train_acc*100, valid_loss, valid_acc*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.40702800154685975 | Test Acc: 50.0% |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print('| Test Loss: {} | Test Acc: {}% |'.format(test_loss, test_acc*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    tokenized = nltk.word_tokenize(sentence)\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    #print(tensor.shape)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    #print(tensor.shape)\n",
    "    prediction = model(tensor)\n",
    "    preds, ind = torch.max(F.softmax(prediction.squeeze(0), dim=-1), 1)\n",
    "\n",
    "    return preds, ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "text = \"My voice range is A2-C5. My chest voice goes up to F4. \" \\\n",
    "       \"Included sample in my higher chest range. What is my voice type?\"\n",
    "print(classes[predict_sentiment(text)[1].item()])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}