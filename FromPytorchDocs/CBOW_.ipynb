{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/smafjal/continuous-bag-of-words-pytorch/blob/master/cbow_model_pytorch.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is CUDA available?\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 46\n",
      "{'beings': 0, 'program.': 1, 'evolve,': 2, 'processes': 3, 'process': 4, 'study': 5, 'that': 6, 'by': 7, 'people': 8, 'data.': 9, 'computer': 10, 'directed': 11, 'effect,': 12, 'conjure': 13, 'programs': 14, 'rules': 15, 'things': 16, 'called': 17, 'direct': 18, 'create': 19, 'to': 20, 'processes.': 21, 'computational': 22, 'spells.': 23, 'spirits': 24, 'other': 25, 'idea': 26, 'inhabit': 27, 'is': 28, 'evolution': 29, 'a': 30, 'are': 31, 'with': 32, 'they': 33, 'as': 34, 'computers.': 35, 'we': 36, 'the': 37, 'process.': 38, 'our': 39, 'pattern': 40, 'abstract': 41, 'manipulate': 42, 'about': 43, 'in': 44, 'of': 45}\n",
      "{0: 'beings', 1: 'program.', 2: 'evolve,', 3: 'processes', 4: 'process', 5: 'study', 6: 'that', 7: 'by', 8: 'people', 9: 'data.', 10: 'computer', 11: 'directed', 12: 'effect,', 13: 'conjure', 14: 'programs', 15: 'rules', 16: 'things', 17: 'called', 18: 'direct', 19: 'create', 20: 'to', 21: 'processes.', 22: 'computational', 23: 'spells.', 24: 'spirits', 25: 'other', 26: 'idea', 27: 'inhabit', 28: 'is', 29: 'evolution', 30: 'a', 31: 'are', 32: 'with', 33: 'they', 34: 'as', 35: 'computers.', 36: 'we', 37: 'the', 38: 'process.', 39: 'our', 40: 'pattern', 41: 'abstract', 42: 'manipulate', 43: 'about', 44: 'in', 45: 'of'}\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "EPOCH = 50\n",
    "VERBOSE = 5\n",
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower().split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\",vocab_size)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {word_to_ix[k]:k for k in word_to_ix}\n",
    "\n",
    "print(word_to_ix)\n",
    "print(ix_to_word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['we', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    #print(\"context\")\n",
    "    #print(context)\n",
    "    #print(\"W2i\")\n",
    "    #print(word_to_ix)\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'to', 'study']\n",
      "tensor([36, 31, 20,  5])\n"
     ]
    }
   ],
   "source": [
    "context, target = data[0]\n",
    "print(context)\n",
    "context_idxs = make_context_vector(context, word_to_ix)\n",
    "print(context_idxs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([1, 80])\n"
     ]
    }
   ],
   "source": [
    "embeds = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "out = embeds(context_idxs)\n",
    "print(out.shape)\n",
    "out = out.view(1,-1)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "lin1 = nn.Linear(CONTEXT_SIZE * 2 * EMBEDDING_DIM, 128)\n",
    "out = lin1(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "ac_fun = nn.ReLU()\n",
    "out = ac_fun(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 46])\n"
     ]
    }
   ],
   "source": [
    "lin2 = nn.Linear(128, vocab_size)\n",
    "out = lin2(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 46])\n"
     ]
    }
   ],
   "source": [
    "ac_fun2 = nn.LogSoftmax(dim = -1)\n",
    "out = ac_fun2(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.0031, -3.9752, -3.8581, -3.5210, -4.0729, -4.1629, -4.1508, -3.4978,\n",
      "         -3.8328, -3.8272, -4.0240, -4.1708, -3.8586, -3.4624, -4.2465, -4.1310,\n",
      "         -3.8688, -3.6987, -3.8868, -3.7290, -3.7423, -3.6906, -3.9477, -3.5691,\n",
      "         -3.9223, -3.8741, -3.7212, -3.6597, -3.6552, -3.7132, -3.6235, -3.7652,\n",
      "         -4.1080, -3.8612, -3.7019, -3.9297, -3.8748, -3.8947, -3.8991, -3.5967,\n",
      "         -3.8162, -3.8327, -4.0893, -4.1568, -3.3259, -4.2275]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor(44)\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(out.argmax())\n",
    "print(ix_to_word[out.argmax().item()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeds = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lin1 = nn.Linear(context_size * 2 * embed_dim, 128)\n",
    "        self.ac_fun1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(128, vocab_size)\n",
    "        self.ac_fun2 = nn.LogSoftmax(dim = -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.embeds(inputs).view(1,-1)    ### This is the most important step. Resizing the tensor\n",
    "        out = self.lin1(out)\n",
    "        out = self.ac_fun1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.ac_fun2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "============================= Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1; Loss 3.8707\n",
      "Epoch 2; Loss 3.7828\n",
      "Epoch 3; Loss 3.6971\n",
      "Epoch 4; Loss 3.6131\n",
      "Epoch 5; Loss 3.5308\n",
      "Epoch 6; Loss 3.4498\n",
      "Epoch 7; Loss 3.3695\n",
      "Epoch 8; Loss 3.2896\n",
      "Epoch 9; Loss 3.2098\n",
      "Epoch 10; Loss 3.1307\n",
      "Epoch 11; Loss 3.0517\n",
      "Epoch 12; Loss 2.9725\n",
      "Epoch 13; Loss 2.8933\n",
      "Epoch 14; Loss 2.8141\n",
      "Epoch 15; Loss 2.7346\n",
      "Epoch 16; Loss 2.6548\n",
      "Epoch 17; Loss 2.5749\n",
      "Epoch 18; Loss 2.4948\n",
      "Epoch 19; Loss 2.4152\n",
      "Epoch 20; Loss 2.3360\n",
      "Epoch 21; Loss 2.2580\n",
      "Epoch 22; Loss 2.1808\n",
      "Epoch 23; Loss 2.1046\n",
      "Epoch 24; Loss 2.0296\n",
      "Epoch 25; Loss 1.9555\n",
      "Epoch 26; Loss 1.8825\n",
      "Epoch 27; Loss 1.8107\n",
      "Epoch 28; Loss 1.7402\n",
      "Epoch 29; Loss 1.6708\n",
      "Epoch 30; Loss 1.6027\n",
      "Epoch 31; Loss 1.5358\n",
      "Epoch 32; Loss 1.4700\n",
      "Epoch 33; Loss 1.4056\n",
      "Epoch 34; Loss 1.3426\n",
      "Epoch 35; Loss 1.2815\n",
      "Epoch 36; Loss 1.2216\n",
      "Epoch 37; Loss 1.1634\n",
      "Epoch 38; Loss 1.1073\n",
      "Epoch 39; Loss 1.0529\n",
      "Epoch 40; Loss 1.0004\n",
      "Epoch 41; Loss 0.9500\n",
      "Epoch 42; Loss 0.9015\n",
      "Epoch 43; Loss 0.8552\n",
      "Epoch 44; Loss 0.8111\n",
      "Epoch 45; Loss 0.7688\n",
      "Epoch 46; Loss 0.7287\n",
      "Epoch 47; Loss 0.6907\n",
      "Epoch 48; Loss 0.6546\n",
      "Epoch 49; Loss 0.6206\n",
      "Epoch 50; Loss 0.5884\n",
      "[3.870683768699909, 3.782829021585399, 3.6971213776489784, 3.613061629492661, 3.530835476414911, 3.4497683500421457, 3.36945536629907, 3.289627958988321, 3.209801299818631, 3.1306862173409296, 3.051663637161255, 2.9725140949775435, 2.893283003363116, 2.8141222267315307, 2.734599304610285, 2.654807199691904, 2.5749409877020737, 2.4948153783535134, 2.4152402939467597, 2.335958587712255, 2.258004427983843, 2.180789380237974, 2.1046020439986526, 2.0295969042284736, 1.9554546095173935, 1.8824997343893708, 1.8107162636929546, 1.7402442796476956, 1.6707569448084667, 1.6027191661555191, 1.5358314891827518, 1.4700067775516674, 1.4056392471338142, 1.3425842788198898, 1.2814924847976914, 1.2215908734962857, 1.1633736714720726, 1.107338634801322, 1.0529111392539123, 1.0004277288399894, 0.9500465822117082, 0.9014766408965506, 0.8552196016856308, 0.8110982237447952, 0.768847272185416, 0.7287395247097673, 0.690722481315506, 0.6546299410020483, 0.6205637217338743, 0.5884243212640285]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_idxs = make_context_vector(context, word_to_ix)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        target_word = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        loss = loss_function(log_probs, target_word)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the python number from a 1-element Tensor\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    mean_loss = total_loss/len(data)\n",
    "    print(\"Epoch {}; Loss {:.4f}\".format(epoch+1, mean_loss))\n",
    "\n",
    "    losses.append(mean_loss)\n",
    "print(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "====================== TEST"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def get_index_of_max(input):\n",
    "    index = 0\n",
    "    for i in range(1, len(input)):\n",
    "        if input[i] > input[index]:\n",
    "            index = i\n",
    "    return index\n",
    "\n",
    "def get_max_prob_result(input, ix_to_word):\n",
    "    return ix_to_word[get_index_of_max(input)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.9367, -5.5674, -5.0082, -4.1530, -4.9800, -4.2173, -4.6565, -4.3320,\n",
      "         -5.2938, -4.9266, -5.2301, -4.9740, -4.4534, -4.7850, -4.3016, -4.8002,\n",
      "         -4.9228, -5.0719, -4.7758, -5.9392, -4.9429, -4.7623, -5.1495, -5.1621,\n",
      "         -4.7104, -5.2874, -4.4092, -4.6519, -4.4553, -4.1950, -3.9179, -6.0036,\n",
      "         -4.3459, -4.9360, -4.7681, -5.0887, -5.8944, -4.8123, -4.8315, -5.8520,\n",
      "         -4.7472, -0.5079, -5.4367, -4.1312, -5.5181, -3.5747]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "context = [\"processes\", \"are\", \"beings\", \"that\" ]\n",
    "context_vector = make_context_vector(context, word_to_ix)\n",
    "a = model(context_vector)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.936703   -5.5673943  -5.0082293  -4.1529584  -4.9800034  -4.217256\n",
      "  -4.656454   -4.3319526  -5.293833   -4.926599   -5.230086   -4.973999\n",
      "  -4.4534297  -4.784968   -4.3015747  -4.8002005  -4.9228454  -5.0718565\n",
      "  -4.775781   -5.939238   -4.942948   -4.762255   -5.1494746  -5.162073\n",
      "  -4.710438   -5.2873507  -4.409164   -4.651874   -4.4553475  -4.1950374\n",
      "  -3.9179158  -6.003648   -4.345876   -4.935962   -4.7681184  -5.0886607\n",
      "  -5.8944197  -4.81225    -4.83149    -5.852008   -4.7472315  -0.50793606\n",
      "  -5.436667   -4.1312275  -5.5180883  -3.57473   ]]\n"
     ]
    }
   ],
   "source": [
    "a = a.data.numpy()\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: we are about to study the idea of a computational process. computational processes are abstract beings that inhabit computers. as they evolve, processes manipulate other abstract things called data. the evolution of a process is directed by a pattern of rules called a program. people create programs to direct processes. in effect, we conjure the spirits of the computer with our spells.\n",
      "\n",
      "Context: ['processes', 'are', 'beings', 'that']\n",
      "\n",
      "Prediction: abstract\n"
     ]
    }
   ],
   "source": [
    "print('Raw text: {}\\n'.format(' '.join(raw_text)))\n",
    "print('Context: {}\\n'.format(context))\n",
    "print('Prediction: {}'.format(get_max_prob_result(a[0], ix_to_word)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}