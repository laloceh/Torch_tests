{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://pytorch.org/tutorials/beginner/nn_tutorial.html#refactor-using-dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the initial dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3  Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0  5.1  3.5  1.4  0.2            1                0               0\n",
      "1  4.9  3.0  1.4  0.2            1                0               0\n",
      "2  4.7  3.2  1.3  0.2            1                0               0\n",
      "3  4.6  3.1  1.5  0.2            1                0               0\n",
      "4  5.0  3.6  1.4  0.2            1                0               0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/iris.data\", header=None)\n",
    "#print(df.head())\n",
    "dum = pd.get_dummies(df[4])\n",
    "#print(dum)\n",
    "df = pd.concat([df, dum], axis=1)\n",
    "df = df.drop([4], axis=1)\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  4.9  3.0  1.4  0.2\n",
      "2  4.7  3.2  1.3  0.2\n",
      "3  4.6  3.1  1.5  0.2\n",
      "4  5.0  3.6  1.4  0.2\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-3]\n",
    "print(X.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0            1                0               0\n",
      "1            1                0               0\n",
      "2            1                0               0\n",
      "3            1                0               0\n",
      "4            1                0               0\n"
     ]
    }
   ],
   "source": [
    "target = df.iloc[:,-3:]\n",
    "print(target.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120, 3)\n",
      "(30, 4)\n",
      "(30, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.20, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform Pandas DF to Tensors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows 120\n",
      "cols: 4\n"
     ]
    }
   ],
   "source": [
    "# Fist transform them to numpy\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Then transform them to Tensors\n",
    "X_train, y_train, X_test, y_test = map( torch.tensor, (X_train, y_train, X_test, y_test))\n",
    "n, c = X_train.shape\n",
    "print(\"Rows\", n)\n",
    "print(\"cols:\", c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the Torch Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the batches without DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i in range((n-1) // BATCH_SIZE + 1 ):\n",
    "        xb, yb = train_ds[i*BATCH_SIZE: i*BATCH_SIZE+BATCH_SIZE]\n",
    "        print(xb.shape, yb.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use a Torch DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n",
      "torch.Size([10, 4]) torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for xb, yb in train_dl:\n",
    "        print(xb.shape, yb.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manage Validation data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ds = TensorDataset(X_test, y_test)\n",
    "#We’ll use a batch size for the validation set that is twice as large as that for the training set.\n",
    "# This is because the validation set does not need backpropagation\n",
    "# and thus takes less memory (it doesn’t need to store the gradients).\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE*2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in test_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(test_dl))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping DataLoader\n",
    "\n",
    "Our CNN is fairly concise, but it only works with MNIST, because:\n",
    "1. It assumes the input is a 28*28 long vector\n",
    "2. It assumes that the final CNN grid size is 4*4 (since that’s the average\n",
    "pooling kernel size we used)\n",
    "\n",
    "Let’s get rid of these two assumptions, so our model works with any 2d single channel image. First, we can remove the initial Lambda layer but moving the data preprocessing into a generator:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    \"\"\"\n",
    "    returns dataloaders for the training and validation sets.\n",
    "    :param train_ds: \n",
    "    :param valid_ds: \n",
    "    :param bs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, test_ds, BATCH_SIZE)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}