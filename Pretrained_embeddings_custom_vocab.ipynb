{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "http://ronny.rest/blog/post_2017_08_04_glove/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from io import open"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "glove_path = \"glove.6B/glove.6B.50d.txt\"\n",
    "EMBEDDING_DIM = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52 unique words\n"
     ]
    }
   ],
   "source": [
    "my_custom_vocab = [\"xxpad\", \"xxunk\", \"xxkno\",\"the\", \"friend\", \"year\", \"when\"]\n",
    "\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower().split()\n",
    "\n",
    "vocabulary = my_custom_vocab + raw_text\n",
    "vocab_size = len(set(vocabulary))\n",
    "print(\"There are {} unique words\".format(vocab_size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'process': 0, 'xxkno': 1, 'pattern': 2, 'they': 3, 'of': 4, 'conjure': 5, 'our': 6, 'to': 7, 'things': 8, 'create': 9, 'process.': 10, 'data.': 11, 'is': 12, 'computer': 13, 'beings': 14, 'abstract': 15, 'computational': 16, 'people': 17, 'a': 18, 'processes': 19, 'evolve,': 20, 'processes.': 21, 'in': 22, 'called': 23, 'other': 24, 'programs': 25, 'inhabit': 26, 'year': 27, 'xxunk': 28, 'directed': 29, 'that': 30, 'manipulate': 31, 'effect,': 32, 'as': 33, 'spirits': 34, 'idea': 35, 'by': 36, 'program.': 37, 'rules': 38, 'when': 39, 'are': 40, 'we': 41, 'spells.': 42, 'xxpad': 43, 'the': 44, 'with': 45, 'evolution': 46, 'direct': 47, 'study': 48, 'about': 49, 'computers.': 50, 'friend': 51}\n",
      "{0: 'process', 1: 'xxkno', 2: 'pattern', 3: 'they', 4: 'of', 5: 'conjure', 6: 'our', 7: 'to', 8: 'things', 9: 'create', 10: 'process.', 11: 'data.', 12: 'is', 13: 'computer', 14: 'beings', 15: 'abstract', 16: 'computational', 17: 'people', 18: 'a', 19: 'processes', 20: 'evolve,', 21: 'processes.', 22: 'in', 23: 'called', 24: 'other', 25: 'programs', 26: 'inhabit', 27: 'year', 28: 'xxunk', 29: 'directed', 30: 'that', 31: 'manipulate', 32: 'effect,', 33: 'as', 34: 'spirits', 35: 'idea', 36: 'by', 37: 'program.', 38: 'rules', 39: 'when', 40: 'are', 41: 'we', 42: 'spells.', 43: 'xxpad', 44: 'the', 45: 'with', 46: 'evolution', 47: 'direct', 48: 'study', 49: 'about', 50: 'computers.', 51: 'friend'}\n"
     ]
    }
   ],
   "source": [
    "word2id = {w:i for i,w in enumerate(set(vocabulary))}\n",
    "id2word = {v:k for k,v in word2id.items()}\n",
    "\n",
    "print(word2id)\n",
    "print(id2word)\n",
    "\n",
    "assert len(id2word) == vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize Embeddings to random values using numpy (this also can be done using Tensorflow)\n",
    "using a variant of Xavier intialization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 50)\n"
     ]
    }
   ],
   "source": [
    "sd = 1/np.sqrt(EMBEDDING_DIM)   # standad deviation to use\n",
    "weights = np.random.normal(0, scale=sd, size=[vocab_size, EMBEDDING_DIM])\n",
    "weights = weights.astype(np.float32)\n",
    "\n",
    "print(weights.shape)\n",
    "#print(weights[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Override the given word vectors from the GloVe text files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 41 words in the glove embeddings\n"
     ]
    }
   ],
   "source": [
    "words_found = 0\n",
    "with open(glove_path, encoding='utf-8', mode=\"r\") as gloveFile:\n",
    "    for line in gloveFile:\n",
    "        #separate the values from the word\n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "\n",
    "        # if word is in our vocab, then update the corresponding weights\n",
    "        id = word2id.get(word, None)\n",
    "        if id is not None:\n",
    "            #print(\"Found custom word {}\".format(word))\n",
    "            weights[id] = np.array(line[1:], dtype=np.float32)\n",
    "            words_found+=1\n",
    "\n",
    "print(\"We found {} words in the glove embeddings\".format(words_found))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Updating embeddings in PyTorch model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 50])\n"
     ]
    }
   ],
   "source": [
    "embeds = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "embeds.weight.data.copy_(torch.Tensor(weights))\n",
    "\n",
    "print(embeds.weight.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1223, -0.0309, -0.2696,  0.0464, -0.1948, -0.2081, -0.0425, -0.1134,\n",
      "         -0.0264, -0.2491, -0.0319,  0.1615, -0.0085, -0.2602,  0.2204, -0.0219,\n",
      "         -0.0119,  0.2183, -0.0733,  0.0914, -0.1902,  0.0796, -0.0485, -0.0789,\n",
      "         -0.0177, -0.1553,  0.1865,  0.0318, -0.1955, -0.0404, -0.1280, -0.1081,\n",
      "          0.1468, -0.0935, -0.1383, -0.1361,  0.1183,  0.2113, -0.1948, -0.0160,\n",
      "         -0.3406, -0.0755, -0.0789,  0.0301, -0.0257,  0.0624,  0.0186, -0.1054,\n",
      "          0.0281, -0.1098]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "w_id = torch.LongTensor([word2id[\"xxkno\"]])\n",
    "print(embeds(w_id))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}